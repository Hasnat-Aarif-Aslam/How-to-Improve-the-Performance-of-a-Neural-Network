* Momentum & NAG uses (Concept of MOMENTUM)

* AdaGrad & RMSProp uses (Concept of Learning Rate)

* ADAM simply combines both concept ðŸ˜Ž

![image](https://github.com/user-attachments/assets/68d3dd48-0867-4bbf-a040-014307415d5d)
